# -*- coding: utf-8 -*-
"""Text_to_images.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Zc0MpAU4Tez9aF2CQcIeJVEAJs97qCQF
"""

import torch
print(torch.cuda.is_available())

"""Text-to-Image Using Stable Diffusion"""

# install req libraries
!pip install -q diffusers transformers accelerate torch safetensors gradio pillow

# import libraries

# import Pytorch
import torch

# import stable diffusion pipeline
from diffusers import StableDiffusionPipeline

# Import image handling library
from PIL import Image

# Import Gradio for the UI
import gradio as gr

# Load the pretrained diffusion model

 # Define the model ID from Hugging face
model_id = "runwayml/stable-diffusion-v1-5"

 # Dectect the GPU is available
device = "cuda" if torch.cuda.is_available() else 'cpu'

# Load the pretrained Stable Diffusion Model
pipe = StableDiffusionPipeline.from_pretrained(
    model_id,
    torch_dtype = torch.float16 if device == 'cuda' else torch.float32
)

#Move the mode to Gpu or cpu
pipe = pipe.to(device)

print(f"Model loaded on {device}")

# DEfine the image Generation Function
def generate_image(prompt):
  """
  Generate an image from a text prompt

  """
  image = pipe(prompt).images[0]
  return image

# Example text prompt
prompt = "A futuristic city at sunset, cyberpunk style"

# Generate image
image = generate_image(prompt)

# Display the generated image
image

# Build the internative web interface using gradio

# Create Gradio interface
interface = gr.Interface(
    fn= generate_image,
    inputs = gr.Textbox(
        lines = 2,
        placeholder = "Enter your prompt here"
    ),

    outputs = "image",
    title = "Text-to-Image Generation Using Stable Diffusion",
    description =" Generate images from text using a pretrained model."
)

# Launch the interface
interface.launch()

